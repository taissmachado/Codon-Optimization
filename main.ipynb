{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: biopython in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.84)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from biopython) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy pandas scikit-learn\n",
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "\n",
    "# Log file setup\n",
    "log_file_path = \"cleaning_log.txt\"\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "log_file = open(log_file_path, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "fna_file = \"Dataset\\CCDS_nucleotide.current.fna\"  \n",
    "faa_file = \"Dataset\\CCDS_protein.current.faa\"     \n",
    "output_clean_fna = \"Dataset\\cleaned_nucleotide_file.fna\"\n",
    "output_clean_faa = \"Dataset\\cleaned_protein_file.faa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse and validate FASTA sequences\n",
    "def parse_fasta(file_path, file_type=\"fna\"):\n",
    "    sequences = {}\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        seq = str(record.seq).upper()  # Normalize to uppercase\n",
    "        if file_type == \"fna\" and all(base in \"ATGC\" for base in seq):  # Validate nucleotides\n",
    "            sequences[record.id] = seq\n",
    "        elif file_type == \"faa\" and all(base in \"ACDEFGHIKLMNPQRSTVWY*\" for base in seq):  # Validate proteins\n",
    "            sequences[record.id] = seq\n",
    "        else:\n",
    "            log_file.write(f\"Invalid sequence in {file_type}: {record.id}\\n\")\n",
    "    return sequences\n",
    "\n",
    "# Function to clean and match FASTA sequences\n",
    "def clean_and_match_fasta(fna_sequences, faa_sequences):\n",
    "    cleaned_fna = {}\n",
    "    cleaned_faa = {}\n",
    "\n",
    "    for seq_id in faa_sequences:\n",
    "        if seq_id in fna_sequences:\n",
    "            nucleotide_seq = Seq(fna_sequences[seq_id])\n",
    "            try:\n",
    "                # Translate the nucleotide sequence\n",
    "                translated_seq = nucleotide_seq.translate(to_stop=True)\n",
    "                # Check if translation matches the protein sequence\n",
    "                if str(translated_seq) == faa_sequences[seq_id]:\n",
    "                    cleaned_fna[seq_id] = fna_sequences[seq_id]\n",
    "                    cleaned_faa[seq_id] = faa_sequences[seq_id]\n",
    "                else:\n",
    "                    log_file.write(f\"Translation mismatch for ID {seq_id}\\n\")\n",
    "            except Exception as e:\n",
    "                log_file.write(f\"Translation error for ID {seq_id}: {e}\\n\")\n",
    "        else:\n",
    "            log_file.write(f\"Missing nucleotide sequence for protein ID {seq_id}\\n\")\n",
    "\n",
    "    # Log any nucleotide sequences with no matching protein\n",
    "    for seq_id in fna_sequences:\n",
    "        if seq_id not in faa_sequences:\n",
    "            log_file.write(f\"Unmatched nucleotide sequence ID {seq_id}\\n\")\n",
    "\n",
    "    return cleaned_fna, cleaned_faa\n",
    "\n",
    "# Function to save cleaned FASTA sequences\n",
    "def save_cleaned_sequences(cleaned_sequences, output_file):\n",
    "    records = []\n",
    "    for seq_id, sequence in cleaned_sequences.items():\n",
    "        record = SeqIO.SeqRecord(Seq(sequence), id=seq_id, description=\"\")\n",
    "        records.append(record)\n",
    "    SeqIO.write(records, output_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 35624 nucleotide sequences.\n",
      "Loaded 35573 protein sequences.\n"
     ]
    }
   ],
   "source": [
    "# Load nucleotide and protein sequences\n",
    "nucleotide_sequences = parse_fasta(fna_file, file_type=\"fna\")\n",
    "protein_sequences = parse_fasta(faa_file, file_type=\"faa\")\n",
    "print(f\"Loaded {len(nucleotide_sequences)} nucleotide sequences.\")\n",
    "print(f\"Loaded {len(protein_sequences)} protein sequences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\Bio\\Seq.py:2879: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 35510 matching nucleotide sequences.\n",
      "Cleaned 35510 matching protein sequences.\n"
     ]
    }
   ],
   "source": [
    "# Clean and match sequences\n",
    "cleaned_nucleotide, cleaned_protein = clean_and_match_fasta(nucleotide_sequences, protein_sequences)\n",
    "print(f\"Cleaned {len(cleaned_nucleotide)} matching nucleotide sequences.\")\n",
    "print(f\"Cleaned {len(cleaned_protein)} matching protein sequences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 30\u001b[0m, in \u001b[0;36mclean_and_match_fasta\u001b[1;34m(fna_sequences, faa_sequences)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m         log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation mismatch for ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     SeqIO\u001b[38;5;241m.\u001b[39mwrite(records, output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Clean and match sequences\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m cleaned_nucleotide, cleaned_protein \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_match_fasta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnucleotide_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotein_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cleaned_nucleotide)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m matching nucleotide sequences.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cleaned_protein)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m matching protein sequences.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 32\u001b[0m, in \u001b[0;36mclean_and_match_fasta\u001b[1;34m(fna_sequences, faa_sequences)\u001b[0m\n\u001b[0;32m     30\u001b[0m             log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation mismatch for ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 32\u001b[0m         log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslation error for ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing nucleotide sequence for protein ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Function to save cleaned sequences to a file\n",
    "def save_cleaned_sequences(cleaned_sequences, output_file):\n",
    "    records = []\n",
    "    for i, sequence in enumerate(cleaned_sequences):\n",
    "        record = SeqRecord(Seq(\"\".join(map(str, sequence))), id=f\"seq{i+1}\", description=\"\")\n",
    "        records.append(record)\n",
    "    SeqIO.write(records, output_file, \"fasta\")\n",
    "\n",
    "# Clean and match sequences\n",
    "cleaned_nucleotide, cleaned_protein = clean_and_match_fasta(nucleotide_sequences, protein_sequences)\n",
    "print(f\"Cleaned {len(cleaned_nucleotide)} matching nucleotide sequences.\")\n",
    "print(f\"Cleaned {len(cleaned_protein)} matching protein sequences.\")\n",
    "\n",
    "# Function to encode nucleotide sequences\n",
    "def encode_nucleotide_sequence(sequence):\n",
    "    mapping = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
    "    encoded_sequence = []\n",
    "    for base in sequence:\n",
    "        if base in mapping:\n",
    "            encoded_sequence.append(mapping[base])\n",
    "        else:\n",
    "            print(f\"Skipping unexpected character '{base}' in sequence.\")\n",
    "    return encoded_sequence\n",
    "\n",
    "# Function to encode protein sequences\n",
    "def encode_protein_sequence(sequence):\n",
    "    mapping = {\n",
    "        'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, 'H': 8, 'I': 9,\n",
    "        'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19\n",
    "    }\n",
    "    encoded_sequence = []\n",
    "    for amino_acid in sequence:\n",
    "        if amino_acid in mapping:\n",
    "            encoded_sequence.append(mapping[amino_acid])\n",
    "        else:\n",
    "            print(f\"Skipping unexpected character '{amino_acid}' in sequence.\")\n",
    "    return encoded_sequence\n",
    "\n",
    "# Function to filter and encode sequences\n",
    "def filter_and_encode_sequences(sequences, encode_function):\n",
    "    encoded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if not seq.startswith('>') and not any(char.isdigit() for char in seq):\n",
    "            encoded_sequences.append(encode_function(seq))\n",
    "    return encoded_sequences\n",
    "\n",
    "# Encode cleaned nucleotide and protein sequences\n",
    "encoded_nucleotide = filter_and_encode_sequences(cleaned_nucleotide, encode_nucleotide_sequence)\n",
    "encoded_protein = filter_and_encode_sequences(cleaned_protein, encode_protein_sequence)\n",
    "\n",
    "# Save cleaned sequences to files\n",
    "save_cleaned_sequences(encoded_nucleotide, output_clean_fna)\n",
    "save_cleaned_sequences(encoded_protein, output_clean_faa)\n",
    "print(f\"Cleaned nucleotide sequences saved to: {output_clean_fna}\")\n",
    "print(f\"Cleaned protein sequences saved to: {output_clean_faa}\")\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codon columns: ['TTT', 'TTC', 'TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG', 'ATT', 'ATC', 'ATA', 'ATG', 'GTT', 'GTC', 'GTA', 'GTG', 'TAT', 'TAC', 'TAA', 'TAG', 'CAT', 'CAC', 'CAA', 'CAG', 'AAT', 'AAC', 'AAA', 'AAG', 'GAT', 'GAC', 'GAA', 'GAG', 'TCT', 'TCC', 'TCA', 'TCG', 'CCT', 'CCC', 'CCA', 'CCG', 'ACT', 'ACC', 'ACA', 'ACG', 'GCT', 'GCC', 'GCA', 'GCG', 'TGT', 'TGC', 'TGA', 'TGG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGT', 'AGC', 'AGA', 'AGG', 'GGT', 'GGC', 'GGA', 'GGG']\n",
      "Tissue indices: torch.Size([53]) tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52])\n",
      "Encoded codons: torch.Size([64, 3]) tensor([[1, 1, 1],\n",
      "        [1, 1, 3],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 2],\n",
      "        [3, 1, 1]])\n",
      "Encoded bicodons: torch.Size([4096, 6]) tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 3],\n",
      "        [1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 2],\n",
      "        [1, 1, 1, 3, 1, 1]])\n",
      "Codon feature tensor shape: torch.Size([53, 64])\n",
      "Bicodon feature tensor shape: torch.Size([53, 4096])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "codon_usage = pd.read_csv(\"Dataset\\\\o537-Tissue_Codon.tsv\", sep='\\t', index_col=0)\n",
    "bicodon_usage = pd.read_csv(\"Dataset\\\\o537-Tissue_Bicod.tsv\", sep='\\t', index_col=0)\n",
    "\n",
    "# Function to encode codons and bicodons\n",
    "def encode_sequence(sequence):\n",
    "    mapping = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
    "    encoded_sequence = []\n",
    "    for base in sequence:\n",
    "        if base in mapping:\n",
    "            encoded_sequence.append(mapping[base])\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected character '{base}' in sequence.\")\n",
    "    return encoded_sequence\n",
    "\n",
    "# Remove the last column in both codon usage and bicodon usage\n",
    "codon_usage = codon_usage.iloc[:, :-1]\n",
    "bicodon_usage = bicodon_usage.iloc[:, :-1]\n",
    "\n",
    "# Encode tissue types (rows) - shared between codon and bicodon datasets\n",
    "tissue_names = codon_usage.index.tolist()  # Assume same tissues for both datasets\n",
    "tissue_encoder = {tissue: idx for idx, tissue in enumerate(tissue_names)}\n",
    "encoded_tissues = [tissue_encoder[tissue] for tissue in tissue_names]\n",
    "\n",
    "# Print codon columns to debug\n",
    "print(\"Codon columns:\", codon_usage.columns.tolist())\n",
    "\n",
    "# Encode codons (columns for codon usage)\n",
    "encoded_codons = [encode_sequence(codon) for codon in codon_usage.columns]\n",
    "\n",
    "# Encode bicodons (columns for bicodon usage)\n",
    "encoded_bicodons = [encode_sequence(bicodon[:3]) + encode_sequence(bicodon[3:]) for bicodon in bicodon_usage.columns]\n",
    "\n",
    "# Convert dataframes to feature tensors\n",
    "codon_feature_matrix = torch.tensor(codon_usage.values, dtype=torch.float32)\n",
    "bicodon_feature_matrix = torch.tensor(bicodon_usage.values, dtype=torch.float32)\n",
    "\n",
    "# Convert encoded tissues, codons, and bicodons into tensors\n",
    "tissue_tensor = torch.tensor(encoded_tissues)\n",
    "codon_tensor = torch.tensor(encoded_codons)\n",
    "bicodon_tensor = torch.tensor(encoded_bicodons)\n",
    "\n",
    "# Display results\n",
    "print(\"Tissue indices:\", tissue_tensor.shape, tissue_tensor)\n",
    "print(\"Encoded codons:\", codon_tensor.shape, codon_tensor[:5])  # Show first 5\n",
    "print(\"Encoded bicodons:\", bicodon_tensor.shape, bicodon_tensor[:5])  # Show first 5\n",
    "print(\"Codon feature tensor shape:\", codon_feature_matrix.shape)\n",
    "print(\"Bicodon feature tensor shape:\", bicodon_feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized codon feature tensor shape: torch.Size([53, 64])\n",
      "Normalized bicodon feature tensor shape: torch.Size([53, 4096])\n",
      "Combined feature tensor shape: torch.Size([53, 4160])\n"
     ]
    }
   ],
   "source": [
    "# Normalize the codon and bicodon tensors\n",
    "def normalize_tensor(tensor):\n",
    "    mean = tensor.mean(dim=0, keepdim=True)\n",
    "    std = tensor.std(dim=0, keepdim=True)\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "# Normalize the codon and bicodon feature matrices\n",
    "normalized_codon_feature_matrix = normalize_tensor(codon_feature_matrix)\n",
    "normalized_bicodon_feature_matrix = normalize_tensor(bicodon_feature_matrix)\n",
    "\n",
    "# Concatenate the normalized codon and bicodon feature matrices along the feature dimension\n",
    "combined_feature_matrix = torch.cat((normalized_codon_feature_matrix, normalized_bicodon_feature_matrix), dim=1)\n",
    "\n",
    "# Display normalized and combined results\n",
    "print(\"Normalized codon feature tensor shape:\", normalized_codon_feature_matrix.shape)\n",
    "print(\"Normalized bicodon feature tensor shape:\", normalized_bicodon_feature_matrix.shape)\n",
    "print(\"Combined feature tensor shape:\", combined_feature_matrix.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
